{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain从入门到实践：构建智能应用的基础框架\n",
    "\n",
    "LangChain是当前大模型应用开发中最流行的框架之一，它为开发者提供了一套完整的工具链，帮助我们更便捷地构建基于大模型的应用。本文将带领读者入门LangChain，掌握其核心概念和基础组件。\n",
    "\n",
    "## 1. LangChain简介\n",
    "\n",
    "LangChain是一个面向大模型的开发框架，旨在简化大模型应用的开发过程。它的核心优势在于：\n",
    "统一了不同模型的调用接口\n",
    "提供了丰富的组件和工具链\n",
    "支持链式处理流程\n",
    "便于集成外部知识和工具\n",
    "\n",
    "LangChain的核心组件包括：\n",
    "\n",
    "模型I/O封装：Chat Models、PromptTemplate、OutputParser等\n",
    "数据连接封装：Document Loaders、Document Transformers、Text Embedding Models、Vectorstores & Retrievers等\n",
    "架构封装：Chain/LCEL、Agent、Tools、LangGraph、LangSmith等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 环境准备\n",
    "\n",
    "在开始前，让我们先安装必要的依赖："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (0.3.12)\n",
      "Requirement already satisfied: python-dotenv in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-openai) (0.3.51)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-openai) (1.70.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.10.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.2.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.49->langchain-openai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\n",
      "Requirement already satisfied: colorama in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 安装LangChain和OpenAI包\n",
    "%pip install langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来创建.env文件，配置OpenAI API密钥："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPENAI_API_KEY=your_api_key_here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型I/O封装\n",
    "\n",
    "### 3.1 模型接口封装\n",
    "\n",
    "LangChain对各种大模型提供了统一的接口，使我们能够轻松切换不同的模型而不用大幅修改代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，旨在回答问题、提供信息和协助解决问题。如果你有任何问题，随时可以问我！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 检查必要的环境变量是否存在\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"请在.env文件中设置OPENAI_API_KEY\")\n",
    "\n",
    "# 初始化模型\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "response = model.invoke(\"你是谁\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 多轮对话封装\n",
    "\n",
    "LangChain提供了标准化的消息类型，用于处理多轮对话："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是学员 kleinSpero。如果你有任何问题或者需要帮助，随时可以告诉我！\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,  # 等价于OpenAI接口中的assistant role\n",
    "    HumanMessage,  # 等价于OpenAI接口中的user role\n",
    "    SystemMessage  # 等价于OpenAI接口中的system role\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是云廷科技的课程助理。\"),\n",
    "    HumanMessage(content=\"我是学员，我叫kleinSpero。\"),\n",
    "    AIMessage(content=\"欢迎！\"),\n",
    "    HumanMessage(content=\"我是谁\")\n",
    "]\n",
    "\n",
    "ret = model.invoke(messages)\n",
    "print(ret.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 更换模型提供商"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain的一大优势是可以轻松切换不同的模型提供商。\n",
    "\n",
    "以DeepSeek模型为例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-deepseek in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (0.1.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-deepseek) (0.3.51)\n",
      "Requirement already satisfied: langchain-openai<1.0.0,>=0.3.9 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-deepseek) (0.3.12)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.3.8)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.10.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (1.70.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (0.8.0)\n",
      "Requirement already satisfied: sniffio in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.27.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (2024.5.15)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (1.2.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (3.4)\n",
      "Requirement already satisfied: certifi in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain-deepseek) (2.3.0)\n",
      "Requirement already satisfied: colorama in d:\\anacanda3\\envs\\pytorch_cuda12_0_py310\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai<1.0.0,>=0.3.9->langchain-deepseek) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "我是DeepSeek Chat，由深度求索公司创造的智能助手！✨ 我的使命是帮助你解答各种问题，无论是学习、工作，还是日常生活中的小困惑。我可以陪你聊天、提供建议、查找资料，甚至帮你分析文件内容。  \n",
      "\n",
      "有什么我可以帮你的吗？😊\n"
     ]
    }
   ],
   "source": [
    "# 安装DeepSeek支持\n",
    "# %pip install langchain-deepseek\n",
    "\n",
    "# 使用DeepSeek模型\n",
    "from langchain.chat_models import init_chat_model\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 检查必要的环境变量是否存在\n",
    "if not os.getenv(\"DEEPSEEK_API_KEY\"):\n",
    "    raise ValueError(\"请在.env文件中设置DEEPSEEK_API_KEY\")\n",
    "\n",
    "model = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")\n",
    "\n",
    "response = model.invoke(\"你是谁\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以Qwen为例:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是通义千问，阿里巴巴集团旗下的超大规模语言模型。我能够回答问题、创作文字，如写故事、公文、邮件、剧本等，还能进行逻辑推理、编程，甚至表达观点和玩游戏。我在多国语言上都有很好的掌握，能为你提供多样化的帮助。有什么我可以帮到你的吗？\n"
     ]
    }
   ],
   "source": [
    "# 使用千问模型\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.llms import Tongyi\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 检查必要的环境变量是否存在\n",
    "if not os.getenv(\"DASHSCOPE_API_KEY\"):\n",
    "    raise ValueError(\"请在.env文件中设置DASHSCOPE_API_KEY\")\n",
    "\n",
    "# 加载 Tongyi 模型\n",
    "model = Tongyi(model_name=\"qwen-turbo\", dashscope_api_key=os.getenv(\"DASHSCOPE_API_KEY\"))  # 使用通义千问qwen-turbo模型\n",
    "\n",
    "response = model.invoke(\"你是谁\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 流式输出\n",
    "\n",
    "对于长回答，流式输出可以提升用户体验："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai、deepseek\n",
    "for token in model.stream(\"你是谁\"):\n",
    "    print(token.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是通义千问，阿里巴巴集团旗下的通义实验室自主研发的超大规模语言模型。我能够回答问题、创作文字，如写故事、公文、邮件、剧本等，还能进行逻辑推理、编程等任务。如果你有任何问题或需要帮助，欢迎随时告诉我！"
     ]
    }
   ],
   "source": [
    "# 通义千问\n",
    "for token in model.stream(\"你是谁\"):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prompt模板\n",
    "\n",
    "### 4.1 基础Prompt模板\n",
    "\n",
    "Prompt模板可以帮助我们统一管理提示词，并支持变量替换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Template===\n",
      "input_variables=['subject'] input_types={} partial_variables={} template='给我讲个关于{subject}的笑话'\n",
      "===Prompt===\n",
      "给我讲个关于小明的笑话\n",
      "小明和他的朋友们一起去郊游，大家都带了好吃的食物。小明带了一筐苹果。\n",
      "\n",
      "大家坐在一起，朋友们开始分享自己的美食。小明一边吃苹果，一边看着朋友们的美味佳肴，心里有点羡慕。\n",
      "\n",
      "他就突然说：“我觉得我的苹果也很好吃！”\n",
      "\n",
      "大家好奇地问：“那你为什么不分享呢？”\n",
      "\n",
      "小明笑着回答：“因为…我怕我的苹果会被偷！这可是我的秘密武器！”\n",
      "\n",
      "朋友们疑惑地问：“什么秘密武器？”\n",
      "\n",
      "小明得意地说：“因为这是我妈特意为我选的，因为她说苹果可以让人聪明！所以我只想自己偷偷享用！”\n",
      "\n",
      "朋友们哈哈大笑，说：“那我们就祝你的秘密武器能让你变得更聪明吧！别忘了也要和我们分享哦！”\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"给我讲个关于{subject}的笑话\")\n",
    "print(\"===Template===\")\n",
    "print(template)\n",
    "print(\"===Prompt===\")\n",
    "print(template.format(subject='小明'))\n",
    "\n",
    "# 使用模板调用LLM\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "ret = llm.invoke(template.format(subject='小明'))\n",
    "print(ret.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 ChatPromptTemplate\n",
    "\n",
    "ChatPromptTemplate用于构建对话式的提示模板："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是AI大模型应用开发的客服助手。你的名字叫小程', additional_kwargs={}, response_metadata={}), HumanMessage(content='你是谁', additional_kwargs={}, response_metadata={})]\n",
      "你可以叫我小程，我是AI大模型应用开发的客服助手。有什么我可以帮助你的吗？\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"你是{product}的客服助手。你的名字叫{name}\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    product=\"AI大模型应用开发\",\n",
    "    name=\"小程\",\n",
    "    query=\"你是谁\"\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "ret = llm.invoke(prompt)\n",
    "print(ret.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 MessagesPlaceholder\n",
    "\n",
    "MessagesPlaceholder用于在模板中预留位置，以便后续填充历史消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Who is Elon Musk?', additional_kwargs={}, response_metadata={}), AIMessage(content='Elon Musk is a billionaire entrepreneur, inventor, and industrial designer', additional_kwargs={}, response_metadata={}), HumanMessage(content='Translate your answer to 中文.', additional_kwargs={}, response_metadata={})]\n",
      "埃隆·马斯克（Elon Musk）是一位亿万富翁企业家、发明家和工业设计师。\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "human_prompt = \"Translate your answer to {language}.\"\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [MessagesPlaceholder(\"history\"), human_message_template]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "# 创建示例对话\n",
    "human_message = HumanMessage(content=\"Who is Elon Musk?\")\n",
    "ai_message = AIMessage(\n",
    "    content=\"Elon Musk is a billionaire entrepreneur, inventor, and industrial designer\"\n",
    ")\n",
    "# 使用模板格式化消息\n",
    "messages = chat_prompt.format_prompt(\n",
    "    history=[human_message, ai_message], language=\"中文\"\n",
    ")\n",
    "# 打印格式化后的消息\n",
    "print(messages.to_messages())\n",
    "\n",
    "result = llm.invoke(messages) \n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 从文件加载Prompt模板\n",
    "\n",
    "对于复杂的Prompt，可以从文件加载："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Template===\n",
      "input_variables=['topic'] input_types={} partial_variables={} template='举一个关于{topic}的例子'\n",
      "===Prompt===\n",
      "举一个关于黑色幽默的例子\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 假设文件内容为: 举一个关于{topic}的例子\n",
    "template = PromptTemplate.from_file(\"./data/prompt/example_prompt_template.txt\")\n",
    "print(\"===Template===\")\n",
    "print(template)\n",
    "print(\"===Prompt===\")\n",
    "print(template.format(topic='黑色幽默'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 结构化输出\n",
    "\n",
    "### 5.1 使用Pydantic对象\n",
    "\n",
    "LangChain可以直接输出Pydantic对象，使API交互更加便捷："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year=2023 month=4 day=6 era='AD'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 定义输出对象结构\n",
    "class Date(BaseModel):\n",
    "    year: int = Field(description=\"Year\")\n",
    "    month: int = Field(description=\"Month\")\n",
    "    day: int = Field(description=\"Day\")\n",
    "    era: str = Field(description=\"BC or AD\")\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "# 定义结构化输出的模型\n",
    "structured_llm = llm.with_structured_output(Date)\n",
    "\n",
    "template = \"\"\"提取用户输入中的日期。\n",
    "用户输入:\n",
    "{query}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "query = \"2023年四月6日天气晴...\"\n",
    "input_prompt = prompt.format_prompt(query=query)\n",
    "\n",
    "result = structured_llm.invoke(input_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 输出JSON格式\n",
    "\n",
    "也可以使用JSON Schema定义输出格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': 2023, 'month': 4, 'day': 6, 'era': 'AD'}\n"
     ]
    }
   ],
   "source": [
    "json_schema = {\n",
    "    \"title\": \"Date\",\n",
    "    \"description\": \"Formated date expression\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"year\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"year, YYYY\",\n",
    "        },\n",
    "        \"month\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"month, MM\",\n",
    "        },\n",
    "        \"day\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"day, DD\",\n",
    "        },\n",
    "        \"era\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"BC or AD\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "structured_llm = llm.with_structured_output(json_schema)\n",
    "\n",
    "result = structured_llm.invoke(input_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 使用OutputParser\n",
    "\n",
    "OutputParser可以解析大模型的输出为指定格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始输出:\n",
      "```json\n",
      "{\"year\": 2023, \"month\": 4, \"day\": 6, \"era\": \"AD\"}\n",
      "```\n",
      "\n",
      "解析后:\n",
      "{'year': 2023, 'month': 4, 'day': 6, 'era': 'AD'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Date)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"提取用户输入中的日期。\\n用户输入:{query}\\n{format_instructions}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "input_prompt = prompt.format_prompt(query=query)\n",
    "output = llm.invoke(input_prompt)\n",
    "print(\"原始输出:\\n\"+output.content)\n",
    "\n",
    "print(\"\\n解析后:\")\n",
    "print(parser.invoke(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用PydanticOutputParser："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始输出:\n",
      "```json\n",
      "{\"year\": 2023, \"month\": 4, \"day\": 6, \"era\": \"AD\"}\n",
      "```\n",
      "\n",
      "解析后:\n",
      "year=2023 month=4 day=6 era='AD'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Date)\n",
    "\n",
    "input_prompt = prompt.format_prompt(query=query)\n",
    "output = llm.invoke(input_prompt)\n",
    "print(\"原始输出:\\n\"+output.content)\n",
    "\n",
    "print(\"\\n解析后:\")\n",
    "print(parser.invoke(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 输出格式纠错\n",
    "\n",
    "OutputFixingParser可以修复格式不正确的输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PydanticOutputParser:\n",
      "Invalid json output: ```json\n",
      "{\"year\": 2023, \"month\": 四, \"day\": 6, \"era\": \"AD\"}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "OutputFixingParser:\n",
      "year=2023 month=4 day=6 era='AD'\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 创建修复解析器\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())\n",
    "# 创建错误数据并测试\n",
    "bad_output = output.content.replace(\"4\",\"四\")\n",
    "# 使用原始解析器尝试解析\n",
    "print(\"PydanticOutputParser:\")\n",
    "try:\n",
    "    parser.invoke(bad_output)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# 使用新的OutputFixingParser解析同样的错误数据\n",
    "print(\"OutputFixingParser:\")\n",
    "print(new_parser.invoke(bad_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Function Calling\n",
    "\n",
    "Function Calling是大模型的重要能力，LangChain提供了便捷的接口："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"name\": \"multiply\",\n",
      "        \"args\": {\n",
      "            \"a\": 3,\n",
      "            \"b\": 4\n",
      "        },\n",
      "        \"id\": \"call_ineEpBk9521v5Bh7TXJDTu8c\",\n",
      "        \"type\": \"tool_call\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# 使用@tool装饰器将普通函数转换为LangChain工具\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.  \n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a: First integer\n",
    "        b: Second integer\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# 绑定工具到模型\n",
    "import json\n",
    "\n",
    "llm_with_tools = llm.bind_tools([add, multiply])\n",
    "\n",
    "query = \"3的4倍是多少?\"\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "output = llm_with_tools.invoke(messages)\n",
    "print(json.dumps(output.tool_calls, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理工具调用结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3的4倍是12。\n"
     ]
    }
   ],
   "source": [
    "# 执行工具调用\n",
    "messages.append(output)\n",
    "\n",
    "available_tools = {\"add\": add, \"multiply\": multiply}\n",
    "\n",
    "for tool_call in output.tool_calls:\n",
    "    selected_tool = available_tools[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "# 再次调用模型处理工具结果\n",
    "result = llm_with_tools.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结\n",
    "\n",
    "本文介绍了LangChain的基础概念和核心组件，包括模型封装、Prompt模板、结构化输出和Function Calling等。这些组件为我们构建大模型应用提供了强大的基础。\n",
    "在后续文章中，我们将继续探索LangChain的高级特性，包括数据连接、向量检索、Chain构建和Agent开发等内容，敬请期待！\n",
    "\n",
    "注意：本文代码使用了最新的LangChain API，如果您使用的是较早版本，可能需要进行相应调整。建议使用最新版本的LangChain以获得最佳体验"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda12_0_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
